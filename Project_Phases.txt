NOTEBOOK: Logistic Regression.ipynb
│
├── FASE 0: Importazione Librerie 
│   └─ [Codice] import pandas as pd, numpy as np, matplotlib.pyplot, seaborn...
│
├── FASE 1: Caricamento del dataset pulito df_EDA.csv 
│   └─ [Codice] df = pd.read_csv("data/df_EDA.csv")
│
├── FASE 2: Ordinal Encoding della variabile categorica ('person_education') 
|           One-Hot Encoding delle restanti variabili categoriche.
│   └─ Motivazione: usare un encoding compatibile con la regressione logistica.
│
├── FASE 3: Separazione X (features) e y (target) 
│   └─ [Codice] X = df.drop('loan_status', axis=1); y = df['loan_status']
│
├── FASE 4: Train/Test Split 
│   └─ [Codice] train_test_split con stratify=y
│
├── FASE 5: Standardizzazione 
│   └─ Per Regressione Logistica. Usa StandardScaler in una pipeline.
│
├── FASE 6: Costruzione della Pipeline 
│   └─ [Codice] Pipeline con StandardScaler + LogisticRegression
    |_ Calcolo VIF (Variance Inflation Factor) per eseguire il funzionamento dell'Inferenza (rimozione > 10)
│
├── FASE 7: Addestramento (fit) del modello 
│
├── FASE 8: Valutazione — Predizione + Matrice Confusione 
│   └─ Accuracy, Recall, Precision, Confusion Matrix, ROC Curve
│
├── FASE 9: Inferenza Statistica con statsmodels 
│   └─ [Codice] sm.Logit per ottenere p-value e coefficienti
│
├── FASE 10: Conclusione e interpretazione 
│   └─ Quali feature influenzano? L'inferenza è significativa? Il modello è utile?
│
└── Grafici: Confusion Matrix, ROC Curve, Coefficienti (barplot con interpretazione) 








NOTEBOOK: Decision Tree.ipynb
│
├── FASE 0: Librerie
├── FASE 1: Caricamento df
├── FASE 2: Ordinal Encoding (come per logistica)
├── FASE 3: X e y
├── FASE 4: Train/Test Split
├── FASE 5: Costruzione modello DecisionTreeClassifier
│   ├── Pre-Pruning (max_depth, min_samples_split, ecc.)
│   └── Cross-Validation
├── FASE 6: Fit + Predict
├── FASE 7: Valutazione con accuracy, confusion matrix, ROC
├── FASE 8: Feature Importance (Gini Importance)
├── FASE 9: Post-Pruning (GridSearchCV o Cost-Complexity Pruning)
├── FASE 10: Conclusione
└── Grafici: Albero, Matrice, Feature Importance, ROC








NOTEBOOK: RandomForest 
│
├── 1. Importazione Librerie
│
├── 2. Preparazione Dataset
│   ├── a. Scelta e codifica variabili categoriche con Ordinal Encoding
│   ├── b. Definizione X (features) e y (target)
│
├── 3. Train-Test Split (stratify = y, 70-30)
│
├── 4. Costruzione Pipeline
│   ├── a. ColumnTransformer con OrdinalEncoder
│   └── b. RandomForestClassifier con class_weight='balanced'
│
├── 5. Addestramento modello
│
├── 6. Valutazione modello
│   ├── Accuracy
│   ├── Precision
│   ├── Recall
│   ├── F1-Score
│   ├── Confusion Matrix + Heatmap
│   ├── ROC Curve + AUC
│
├── 7. Importanza delle feature
│   └── Classifica variabili più importanti (grafico + interpretazione)
│
└── 8. Conclusione
    ├── Confronto finale con altri modelli
    └── Interpretazione dei risultati per decidere se è il miglior modello







NOTEBOOK: Neural Network.ipynb
├── Librerie (tensorflow.keras)
├── Dataset
├── Encoding
├── Standardizzazione
├── Separazione X/y
├── Costruzione modello sequenziale:
│   ├── Dense
│   ├── Activation Function (ReLU, Sigmoid)
│   ├── Loss Function (categorical crossentropy o binary crossentropy)
│   ├── Ottimizzatore (Adam con learning_rate)
├── Compilazione e Fit (epochs, batch_size)
├── Valutazione Accuracy
├── Confusion Matrix
├── Grafico della Loss e Accuracy durante gli Epoch
├── Funzione di attivazione e costo — spiegazione
├── Backpropagation (concetto)
└── Conclusione